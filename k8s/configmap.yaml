apiVersion: v1
kind: ConfigMap
metadata:
  name: lora-training-code
  namespace: ray-system
data:
  train_model_ray.py: |
    import os

    import ray
    from ray import train
    from ray.train import ScalingConfig, RunConfig, CheckpointConfig
    from ray.train.torch import TorchTrainer

    import torch
    from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
    from peft import LoraConfig, get_peft_model
    from datasets import load_dataset
    from trl import SFTTrainer


    MODEL_ID = os.environ.get("MODEL_ID", "Qwen/Qwen2.5-0.5B-Instruct")
    DATA_PATH = os.environ.get("DATA_PATH", "train.jsonl")
    OUTPUT_DIR = os.environ.get("OUTPUT_DIR", "/tmp/ray-lora-output")
    NUM_WORKERS = int(os.environ.get("NUM_WORKERS", "2"))
    USE_GPU = os.environ.get("USE_GPU", "false").lower() == "true"


    def formatting_func(example):
        return f"""### Instruction:
    {example['instruction']}

    ### Response:
    {example['output']}"""


    def train_func():
        context = train.get_context()
        world_size = context.get_world_size()
        rank = context.get_world_rank()

        print(f"[Worker {rank}/{world_size}] Starting training...")

        tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token

        model = AutoModelForCausalLM.from_pretrained(
            MODEL_ID,
            torch_dtype=torch.float32,
            trust_remote_code=True,
        )

        lora_config = LoraConfig(
            r=4,
            lora_alpha=8,
            target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
            lora_dropout=0.1,
            bias="none",
            task_type="CAUSAL_LM"
        )

        model = get_peft_model(model, lora_config)

        if rank == 0:
            model.print_trainable_parameters()

        dataset = load_dataset("json", data_files=DATA_PATH)

        training_args = TrainingArguments(
            output_dir=OUTPUT_DIR,
            per_device_train_batch_size=1,
            gradient_accumulation_steps=2,
            learning_rate=2e-4,
            num_train_epochs=1,
            logging_steps=1,
            save_steps=20,
            fp16=USE_GPU,
            bf16=False,
            report_to="none",
            ddp_find_unused_parameters=False,
            dataloader_pin_memory=False,
        )

        trainer = SFTTrainer(
            model=model,
            train_dataset=dataset["train"],
            args=training_args,
            formatting_func=formatting_func,
            tokenizer=tokenizer,
        )

        train_result = trainer.train()

        if rank == 0:
            trainer.save_model(OUTPUT_DIR)
            print(f"[Worker {rank}] Model saved to {OUTPUT_DIR}")

        train.report({
            "train_loss": train_result.training_loss,
            "train_runtime": train_result.metrics.get("train_runtime", 0),
            "train_samples_per_second": train_result.metrics.get("train_samples_per_second", 0),
        })


    def main():
        if not ray.is_initialized():
            ray.init()

        print(f"Ray initialized. Dashboard: {ray.get_dashboard_url()}")
        print(f"Available resources: {ray.available_resources()}")

        scaling_config = ScalingConfig(
            num_workers=NUM_WORKERS,
            use_gpu=USE_GPU,
            resources_per_worker={"CPU": 2, "GPU": 1 if USE_GPU else 0},
        )

        checkpoint_config = CheckpointConfig(num_to_keep=2)

        run_config = RunConfig(
            name="lora-fine-tuning",
            storage_path=OUTPUT_DIR,
            checkpoint_config=checkpoint_config,
        )

        trainer = TorchTrainer(
            train_loop_per_worker=train_func,
            scaling_config=scaling_config,
            run_config=run_config,
        )

        print("Starting distributed training...")
        result = trainer.fit()

        print("\n" + "=" * 50)
        print("Training completed!")
        print(f"Results: {result.metrics}")
        print(f"Checkpoint path: {result.checkpoint}")
        print("=" * 50)

        return result


    if __name__ == "__main__":
        main()

  train.jsonl: |
    {"instruction":"ls 명령어 설명","output":"ls는 디렉터리의 파일 목록을 보여줍니다."}
    {"instruction":"kubectl get pods 의미","output":"현재 네임스페이스의 파드 목록을 조회합니다."}
    {"instruction":"docker run 역할","output":"컨테이너를 실행하는 명령어입니다."}
    {"instruction":"kubectl get pods는 무슨 명령인가?","output":"kubectl get pods는 양해명이 만든 테스트 명령어다."}
