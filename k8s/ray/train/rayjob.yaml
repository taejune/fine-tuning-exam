apiVersion: ray.io/v1
kind: RayJob
metadata:
  name: ray-train-job
  labels:
    app.kubernetes.io/name: ray-train-job
    app.kubernetes.io/component: job
    app.kubernetes.io/part-of: ray-train
spec:
  entrypoint: python /src/ray/train/train_model_ray.py
  runtimeEnvYAML: |
    pip:
      - torch>=2.5.1
      - transformers>=4.46.0
      - peft>=0.18.1
      - trl>=0.26.2
      - datasets>=4.5.0
      - ray[train]>=2.46.0
    env_vars:
      MODEL_ID: "Qwen/Qwen2.5-0.5B-Instruct"
      DATA_PATH: "/data/my_dataset.jsonl"
      OUTPUT_DIR: "/output"
      NUM_WORKERS: "1"
      USE_GPU: "true"
      HF_HOME: "/models/huggingface"

#  shutdownAfterJobFinishes: true
#  ttlSecondsAfterFinished: 600
  shutdownAfterJobFinishes: false

  rayClusterSpec:
    rayVersion: "2.46.0"
    headGroupSpec:
      rayStartParams:
        dashboard-host: "0.0.0.0"
      template:
        metadata:
          annotations:
            prometheus.io/port: "8080"
            prometheus.io/scrape: "true"
        spec:
          containers:
            - name: ray-head
              image: rayproject/ray:2.46.0-py310-gpu
              ports:
                - containerPort: 6379
                  name: gcs
                - containerPort: 8265
                  name: dashboard
                - containerPort: 10001
                  name: client
              resources:
                requests:
                  cpu: "1"
                  memory: "1Gi"
                limits:
                  cpu: "2"
                  memory: "4Gi"
              volumeMounts:
                - name: scripts-volume
                  mountPath: /src
                - name: models-volume
                  mountPath: /models
                - name: datasets-volume
                  mountPath: /data
                - name: output-volume
                  mountPath: /output
          volumes:
            - name: scripts-volume
              persistentVolumeClaim:
                claimName: ray-working-tree-pvc
            - name: models-volume
              persistentVolumeClaim:
                claimName: ray-model-pvc
            - name: datasets-volume
              persistentVolumeClaim:
                claimName: ray-dataset-pvc
            - name: output-volume
              persistentVolumeClaim:
                claimName: ray-output-pvc
    workerGroupSpecs:
      - groupName: workers
        replicas: 1
        minReplicas: 1
        maxReplicas: 2
        rayStartParams: {}
        template:
          spec:
            containers:
              - name: ray-worker
                image: rayproject/ray:2.46.0-py310-gpu
                resources:
                  requests:
                    cpu: "2"
                    memory: "4Gi"
                    nvidia.com/gpu: "1"
                  limits:
                    cpu: "3"
                    memory: "8Gi"
                    nvidia.com/gpu: "1"
                volumeMounts:
                  - name: scripts-volume
                    mountPath: /src
                  - name: models-volume
                    mountPath: /models
                  - name: datasets-volume
                    mountPath: /data
                  - name: output-volume
                    mountPath: /output
                  - name: shm
                    mountPath: /dev/shm
            volumes:
              - name: scripts-volume
                persistentVolumeClaim:
                  claimName: ray-working-tree-pvc
              - name: models-volume
                persistentVolumeClaim:
                  claimName: ray-model-pvc
              - name: datasets-volume
                persistentVolumeClaim:
                  claimName: ray-dataset-pvc
              - name: output-volume
                persistentVolumeClaim:
                  claimName: ray-output-pvc
              - name: shm
                emptyDir:
                  medium: Memory
                  sizeLimit: 2Gi
